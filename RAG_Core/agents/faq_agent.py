# RAG_Core/agents/faq_agent.py (NO FALLBACK VERSION)

from typing import Dict, Any, List
from models.llm_model import llm_model
from tools.vector_search import search_faq, rerank_faq
from config.settings import settings
import logging

logger = logging.getLogger(__name__)


class FAQAgent:
    def __init__(self):
        self.name = "FAQ"

        # NgÆ°á»¡ng cho cÃ¡c giai Ä‘oáº¡n khÃ¡c nhau
        self.vector_threshold = 0.5
        self.rerank_threshold = 0.6
        self.direct_answer_threshold = 0.75
        self.force_similarity_threshold = 0.85
        self.use_llm = True

        self.standard_prompt = """Báº¡n lÃ  má»™t chuyÃªn viÃªn tÆ° váº¥n khÃ¡ch hÃ ng ngÆ°á»i Viá»‡t Nam thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p.

CÃ¢u há»i ngÆ°á»i dÃ¹ng: "{question}"

Káº¿t quáº£ tÃ¬m kiáº¿m FAQ (Ä‘Ã£ Ä‘Æ°á»£c rerank):
{faq_results}

HÆ°á»›ng dáº«n:
1. Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c sáº¯p xáº¿p theo Ä‘á»™ phÃ¹ há»£p (rerank_score)
2. Náº¿u FAQ Ä‘áº§u tiÃªn cÃ³ rerank_score > {rerank_threshold}, hÃ£y tráº£ lá»i dá»±a trÃªn Ä‘Ã³
3. Náº¿u khÃ´ng cÃ³ FAQ phÃ¹ há»£p, tráº£ vá» "NOT_FOUND"
4. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n vÃ  chÃ­nh xÃ¡c
5. CÃ³ thá»ƒ káº¿t há»£p thÃ´ng tin tá»« nhiá»u FAQ náº¿u cáº§n

Tráº£ lá»i:"""

    def process(
            self,
            question: str,
            is_followup: bool = False,
            context: str = "",
            **kwargs
    ) -> Dict[str, Any]:
        """
        Xá»­ lÃ½ cÃ¢u há»i FAQ - KHÃ”NG CÃ“ FALLBACK
        Náº¿u reranking fail â†’ propagate error
        """
        try:
            # ===============================================
            # BÆ¯á»šC 1: VECTOR SEARCH
            # ===============================================
            logger.info(f"Step 1: Vector search for FAQ with threshold={self.vector_threshold}")
            faq_results = search_faq.invoke({"query": question})

            if not faq_results or "error" in str(faq_results):
                logger.warning("FAQ vector search failed or returned error")
                return self._route_to_retriever("Vector search failed")

            # Lá»c theo vector threshold
            filtered_faqs = [
                faq for faq in faq_results
                if faq.get("similarity_score", 0) >= self.vector_threshold
            ]

            if not filtered_faqs:
                logger.info(f"No FAQ passed vector threshold {self.vector_threshold}")
                return self._route_to_retriever("No FAQ above vector threshold")

            logger.info(f"Found {len(filtered_faqs)} FAQs above vector threshold")

            # ===============================================
            # BÆ¯á»šC 2: RERANK (NO FALLBACK)
            # ===============================================
            logger.info("Step 2: Reranking FAQs with cross-encoder")

            reranked_faqs = rerank_faq.invoke({
                "query": question,
                "faq_results": filtered_faqs
            })

            if not reranked_faqs:
                logger.error("âŒ Reranking returned empty results - should not happen")
                raise RuntimeError("FAQ reranking failed: empty results")

            best_faq = reranked_faqs[0]
            rerank_score = best_faq.get("rerank_score", 0)
            similarity_score = best_faq.get("similarity_score", 0)

            logger.info(
                f"Best FAQ: rerank={rerank_score:.3f}, similarity={similarity_score:.3f}"
            )

            # ===============================================
            # BÆ¯á»šC 3: CHECK THRESHOLD
            # ===============================================
            is_confident = (
                similarity_score >= self.force_similarity_threshold
            )

            if not is_confident:
                logger.info(
                    f"Rerank {rerank_score:.3f} < {self.rerank_threshold} AND "
                    f"similarity {similarity_score:.3f} < {self.force_similarity_threshold} â†’ RETRIEVER"
                )
                return self._route_to_retriever(
                    f"Not confident: rerank={rerank_score:.3f}, sim={similarity_score:.3f}"
                )

            # ===============================================
            # BÆ¯á»šC 4: TRáº¢ Lá»œI TRá»°C TIáº¾P HAY QUA LLM
            # ===============================================
            if (
                    rerank_score >= self.direct_answer_threshold
                    or similarity_score >= self.force_similarity_threshold
            ):
                logger.info(
                    f"âœ… DIRECT ANSWER: rerank={rerank_score:.3f}, sim={similarity_score:.3f}"
                )

                answer = self._format_direct_answer(best_faq, question)

                return {
                    "status": "SUCCESS",
                    "answer": answer,
                    "mode": "direct",
                    "references": [
                        {
                            "document_id": best_faq.get("faq_id"),
                            "type": "FAQ",
                            "description": best_faq.get("question", "")[:500],  # ThÃªm description
                            "rerank_score": round(rerank_score, 4),
                            "similarity_score": round(similarity_score, 4)
                        }
                    ],
                    "next_agent": "end"
                }

            # ===============================================
            # BÆ¯á»šC 5: DÃ™NG LLM
            # ===============================================
            logger.info(
                f"ðŸ¤– LLM MODE: rerank={rerank_score:.3f}, sim={similarity_score:.3f}"
            )

            faq_text = self._format_reranked_faq(reranked_faqs[:3])

            prompt = self.standard_prompt.format(
                question=question,
                faq_results=faq_text,
                rerank_threshold=self.rerank_threshold
            )

            response = llm_model.invoke(prompt)

            if "NOT_FOUND" in response.upper():
                logger.info("LLM determined FAQ not sufficient")
                return self._route_to_retriever("LLM rejected FAQ")

            if not response or len(response.strip()) < 10:
                logger.warning("Generated answer too short")
                return self._route_to_retriever("Answer too short")

            logger.info(f"FAQ answer generated via LLM (rerank={rerank_score:.3f})")

            return {
                "status": "SUCCESS",
                "answer": response,
                "mode": "llm",
                "references": [
                    {
                        "document_id": best_faq.get("faq_id"),
                        "type": "FAQ",
                        "description": best_faq.get("question", "")[:500],
                        "rerank_score": round(rerank_score, 4),
                        "similarity_score": round(similarity_score, 4)
                    }
                ],
                "next_agent": "end"
            }

        except RuntimeError as e:
            # Critical errors (reranking fails) - propagate
            logger.error(f"âŒ Critical FAQ error: {e}")
            raise

        except Exception as e:
            # Other errors - also propagate
            logger.error(f"âŒ Unexpected error in FAQ agent: {e}", exc_info=True)
            raise RuntimeError(f"FAQ agent failed: {e}") from e

    # ===============================================================
    # Helper Functions
    # ===============================================================

    def _format_direct_answer(self, faq: Dict[str, Any], question: str) -> str:
        """Format cÃ¢u tráº£ lá»i trá»±c tiáº¿p"""
        return f"{faq.get('answer', '')}"

    def _format_reranked_faq(self, faq_results: List[Dict[str, Any]]) -> str:
        """Format FAQ Ä‘Ã£ Ä‘Æ°á»£c rerank"""
        if not faq_results:
            return "KhÃ´ng tÃ¬m tháº¥y FAQ phÃ¹ há»£p"

        formatted_lines = []
        for i, faq in enumerate(faq_results, 1):
            question = faq.get('question', '')
            answer = faq.get('answer', '')
            rerank_score = faq.get('rerank_score', 0)
            similarity_score = faq.get('similarity_score', 0)

            formatted_lines.append(
                f"FAQ {i} (Rerank: {rerank_score:.3f}, Similarity: {similarity_score:.3f}):\n"
                f"Q: {question}\n"
                f"A: {answer}\n"
            )

        return "\n".join(formatted_lines)

    def _route_to_retriever(self, reason: str) -> Dict[str, Any]:
        logger.info(f"Routing to RETRIEVER: {reason}")
        return {
            "status": "NOT_FOUND",
            "answer": "",
            "references": [],
            "next_agent": "RETRIEVER"
        }

    def set_thresholds(
            self,
            vector_threshold: float = None,
            rerank_threshold: float = None,
            direct_answer_threshold: float = None,
            use_llm: bool = None
    ):
        if vector_threshold is not None:
            self.vector_threshold = vector_threshold
            logger.info(f"Vector threshold updated to {vector_threshold}")

        if rerank_threshold is not None:
            self.rerank_threshold = rerank_threshold
            logger.info(f"Rerank threshold updated to {rerank_threshold}")

        if direct_answer_threshold is not None:
            self.direct_answer_threshold = direct_answer_threshold
            logger.info(f"Direct answer threshold updated to {direct_answer_threshold}")

        if use_llm is not None:
            self.use_llm = use_llm
            logger.info(f"Use LLM mode: {use_llm}")